{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nibabel\n",
    "!pip install -U scikit-learn\n",
    "!pip install torch torchvision\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import tarfile\n",
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, modalities, fraction=1.0):\n",
    "    data_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    patient_folders = os.listdir(data_path)\n",
    "    random.shuffle(patient_folders)\n",
    "    num_patients = int(len(patient_folders) * fraction)\n",
    "    selected_patients = patient_folders[:num_patients]\n",
    "\n",
    "    for patient_folder in selected_patients:\n",
    "        patient_path = os.path.join(data_path, patient_folder)\n",
    "\n",
    "        image_data = []\n",
    "        for modality in modalities:\n",
    "            modality_file = os.path.join(patient_path, f\"{patient_folder}_{modality}.nii.gz\")\n",
    "            modality_data = nib.load(modality_file).get_fdata(dtype=np.float32)  # Add dtype=np.float32\n",
    "            image_data.append(modality_data)\n",
    "\n",
    "        mask_file = os.path.join(patient_path, f\"{patient_folder}_seg.nii.gz\")\n",
    "        mask_data = nib.load(mask_file).get_fdata()\n",
    "\n",
    "        data_list.append(np.stack(image_data, axis=-1))\n",
    "        mask_list.append(mask_data)\n",
    "\n",
    "    return np.array(data_list), np.array(mask_list)\n",
    "\n",
    "def generate_modality_combinations(modalities):\n",
    "    combinations_list = []\n",
    "    for i in range(1, len(modalities) + 1):\n",
    "        for subset in combinations(modalities, i):\n",
    "            combinations_list.append(list(subset))\n",
    "    return combinations_list\n",
    "\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 32)\n",
    "        self.enc2 = self.conv_block(32, 64)\n",
    "        self.enc3 = self.conv_block(64, 128)\n",
    "        self.enc4 = self.conv_block(128, 256)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv3 = self.upconv_block(256, 128)\n",
    "        self.dec3 = self.conv_block(256, 128)\n",
    "        self.upconv2 = self.upconv_block(128, 64)\n",
    "        self.dec2 = self.conv_block(128, 64)\n",
    "        self.upconv1 = self.upconv_block(64, 32)\n",
    "        self.dec1 = self.conv_block(64, 32)\n",
    "        \n",
    "        self.out_conv = nn.Conv3d(32, out_channels, kernel_size=1)\n",
    "    \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        dec3 = self.dec3(torch.cat((self.upconv3(enc4), enc3), dim=1))\n",
    "        dec2 = self.dec2(torch.cat((self.upconv2(dec3), enc2), dim=1))\n",
    "        dec1 = self.dec1(torch.cat((self.upconv1(dec2), enc1), dim=1))\n",
    "        \n",
    "        return self.out_conv(dec1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "data_path = os.path.join(current_directory, \"data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "!pip install kaggle\n",
    "\n",
    "%env KAGGLE_USERNAME=ihindal\n",
    "%env KAGGLE_KEY=549e8a0e9862683f6f255cb289ece9de\n",
    "import kaggle\n",
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"dschettler8845/brats-2021-task1\", \"-p\", data_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "# Set the data path\n",
    "data_path = \"/content/drive/MyDrive/brats\"\n",
    "\n",
    "# Unzip the dataset\n",
    "zip_file_path = os.path.join(data_path, \"brats-2021-task1.zip\")\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n",
    "\n",
    "# Create a new directory for the dataset\n",
    "dataset_path = os.path.join(data_path, \"dataset\")\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "# Untar the dataset\n",
    "tar_file_path = os.path.join(data_path, \"BraTS2021_Training_Data.tar\")\n",
    "with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
    "    tar_ref.extractall(dataset_path)\n",
    "\n",
    "# Set the data path\n",
    "data_path = dataset_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "all_modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "modality_combinations = generate_modality_combinations(all_modalities)\n",
    "\n",
    "batch_size_per_gpu = 4\n",
    "num_gpus = 1\n",
    "total_batch_size = batch_size_per_gpu * num_gpus\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loop through all possible combinations of modalities\n",
    "for modalities in modality_combinations:\n",
    "    print(f\"Training with modalities: {modalities}\")\n",
    "\n",
    "    # Load the data\n",
    "    fraction = 0.1\n",
    "    X, y = load_data(data_path, modalities, fraction)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create the model\n",
    "    model = UNet3D(len(modalities), 1).to(device)\n",
    "\n",
    "    # Scale the learning rate\n",
    "    lr = 1e-3 * (total_batch_size / 16)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Set up the TensorBoard writer\n",
    "    writer = SummaryWriter(log_dir=f'./logs/3DUNet_{\"_\".join(modalities)}')\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(X_train), batch_size_per_gpu):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = torch.from_numpy(X_train[i:i + batch_size_per_gpu]).to(device)\n",
    "            labels = torch.from_numpy(y_train[i:i + batch_size_per_gpu]).unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(X_train)\n",
    "        writer.add_scalar('train_loss', epoch_loss, epoch)\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_val), batch_size_per_gpu):\n",
    "                inputs = torch.from_numpy(X_val[i:i + batch_size_per_gpu]).to(device)\n",
    "                labels = torch.from_numpy(y_val[i:i + batch_size_per_gpu]).unsqueeze(1).to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(X_val)\n",
    "        writer.add_scalar('val_loss', val_loss, epoch)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f'3DUNet_{\"_\".join(modalities)}.pth')\n",
    "    writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
