{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nibabel\n",
    "!pip install -U scikit-learn\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import tarfile\n",
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow as tf\n",
    "import subprocess\n",
    "\n",
    "# Enable mixed precision training\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(data_path, modalities, fraction=1.0):\n",
    "    data_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    patient_folders = os.listdir(data_path)\n",
    "    random.shuffle(patient_folders)\n",
    "    num_patients = int(len(patient_folders) * fraction)\n",
    "    selected_patients = patient_folders[:num_patients]\n",
    "\n",
    "    for patient_folder in selected_patients:\n",
    "        patient_path = os.path.join(data_path, patient_folder)\n",
    "\n",
    "        image_data = []\n",
    "        for modality in modalities:\n",
    "            modality_file = os.path.join(patient_path, f\"{patient_folder}_{modality}.nii.gz\")\n",
    "            modality_data = nib.load(modality_file).get_fdata(dtype=np.float32)  # Add dtype=np.float32\n",
    "            image_data.append(modality_data)\n",
    "\n",
    "        mask_file = os.path.join(patient_path, f\"{patient_folder}_seg.nii.gz\")\n",
    "        mask_data = nib.load(mask_file).get_fdata()\n",
    "\n",
    "        data_list.append(np.stack(image_data, axis=-1))\n",
    "        mask_list.append(mask_data)\n",
    "\n",
    "    return np.array(data_list), np.array(mask_list)\n",
    "\n",
    "# Create segmentation model\n",
    "def create_segmentation_model(input_shape, base_model_name):\n",
    "    input_shape = (*input_shape, len(modalities))  # Add this line to update input_shape\n",
    "    base_model = tf.keras.applications.ResNet50V2(input_shape=input_shape, include_top=False, weights=None)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_modality_combinations(modalities):\n",
    "    combinations_list = []\n",
    "    for i in range(1, len(modalities) + 1):\n",
    "        for subset in combinations(modalities, i):\n",
    "            combinations_list.append(list(subset))\n",
    "    return combinations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "data_path = os.path.join(current_directory, \"data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "%env KAGGLE_USERNAME=ihindal\n",
    "%env KAGGLE_KEY=549e8a0e9862683f6f255cb289ece9de\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"dschettler8845/brats-2021-task1\", \"-p\", data_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "zip_file_path = os.path.join(data_path, \"brats-2021-task1.zip\")\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'dataset' subfolder inside the data_path directory\n",
    "dataset_path = os.path.join(data_path, \"dataset\")\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "# Extract the files into the 'dataset' subfolder\n",
    "tar_file_path = os.path.join(data_path, \"BraTS2021_Training_Data.tar\")\n",
    "with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
    "    tar_ref.extractall(dataset_path)\n",
    "\n",
    "# Update the data_path variable to point to the 'dataset' subfolder\n",
    "data_path = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "all_modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "modality_combinations = generate_modality_combinations(all_modalities)\n",
    "base_model_name = \"ResNet50V2\"\n",
    "\n",
    "# Increase batch size per GPU\n",
    "batch_size_per_gpu = 4\n",
    "num_gpus = 1\n",
    "total_batch_size = batch_size_per_gpu * num_gpus\n",
    "\n",
    "# Loop through all possible combinations of modalities\n",
    "for modalities in modality_combinations:\n",
    "    print(f\"Training with modalities: {modalities}\")\n",
    "\n",
    "    # Load the data\n",
    "    fraction = 0.1\n",
    "    X, y = load_data(data_path, modalities, fraction)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = create_segmentation_model(input_shape=X_train.shape[1:], base_model_name=base_model_name)\n",
    "\n",
    "    # Scale the learning rate\n",
    "    lr = 1e-3 * (total_batch_size / 16)\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Set up the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=f'./logs/{base_model_name}_{\"_\".join(modalities)}',\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        update_freq='epoch',\n",
    "        profile_batch=2,\n",
    "        embeddings_freq=1\n",
    "    )\n",
    "\n",
    "    # Set up the ReduceLROnPlateau callback\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, mode='min')\n",
    "\n",
    "    # Set up the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='min', restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size_per_gpu,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[tensorboard_callback, reduce_lr, early_stopping]\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'{base_model_name}_{\"_\".join(modalities)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
